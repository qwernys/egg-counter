{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2781d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <0B7EB158-53DC-3403-8A49-22178CAB4612> /opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/egg-counter/lib/python3.10/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/egg-counter/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary (fused): 72 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\n",
      "0: 384x640 18 Eggs, 96.8ms\n",
      "Speed: 11.1ms preprocess, 96.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinjonsson/Desktop/ByteTrack/yolox/tracker/byte_tracker.py:182: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729647065806/work/aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  dets_second = bboxes[inds_second]\n",
      "/Users/kevinjonsson/Desktop/ByteTrack/yolox/tracker/byte_tracker.py:185: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729647065806/work/aten/src/ATen/native/IndexingUtils.h:28.)\n",
      "  scores_second = scores[inds_second]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 18 Eggs, 139.7ms\n",
      "Speed: 2.9ms preprocess, 139.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 74.1ms\n",
      "Speed: 2.6ms preprocess, 74.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 123.1ms\n",
      "Speed: 3.2ms preprocess, 123.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 84.8ms\n",
      "Speed: 2.5ms preprocess, 84.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 80.9ms\n",
      "Speed: 3.2ms preprocess, 80.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.2ms\n",
      "Speed: 1.9ms preprocess, 77.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 87.0ms\n",
      "Speed: 1.9ms preprocess, 87.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 75.9ms\n",
      "Speed: 1.6ms preprocess, 75.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 85.6ms\n",
      "Speed: 1.8ms preprocess, 85.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 80.6ms\n",
      "Speed: 2.0ms preprocess, 80.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 84.1ms\n",
      "Speed: 2.5ms preprocess, 84.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 81.2ms\n",
      "Speed: 2.2ms preprocess, 81.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.7ms\n",
      "Speed: 1.6ms preprocess, 79.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 81.3ms\n",
      "Speed: 2.0ms preprocess, 81.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 80.3ms\n",
      "Speed: 2.0ms preprocess, 80.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 78.6ms\n",
      "Speed: 1.9ms preprocess, 78.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 76.6ms\n",
      "Speed: 1.5ms preprocess, 76.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 74.5ms\n",
      "Speed: 1.2ms preprocess, 74.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.6ms\n",
      "Speed: 2.0ms preprocess, 77.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.8ms\n",
      "Speed: 1.7ms preprocess, 77.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.1ms\n",
      "Speed: 1.9ms preprocess, 79.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.2ms\n",
      "Speed: 1.9ms preprocess, 77.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 80.5ms\n",
      "Speed: 1.8ms preprocess, 80.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 71.0ms\n",
      "Speed: 1.5ms preprocess, 71.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 83.0ms\n",
      "Speed: 1.8ms preprocess, 83.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.3ms\n",
      "Speed: 2.3ms preprocess, 78.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 85.3ms\n",
      "Speed: 2.1ms preprocess, 85.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.3ms\n",
      "Speed: 1.6ms preprocess, 77.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.6ms\n",
      "Speed: 2.0ms preprocess, 77.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.0ms\n",
      "Speed: 1.7ms preprocess, 78.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 75.9ms\n",
      "Speed: 1.5ms preprocess, 75.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 76.7ms\n",
      "Speed: 1.7ms preprocess, 76.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 82.3ms\n",
      "Speed: 1.7ms preprocess, 82.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 74.0ms\n",
      "Speed: 1.8ms preprocess, 74.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.9ms\n",
      "Speed: 1.8ms preprocess, 78.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 73.8ms\n",
      "Speed: 1.9ms preprocess, 73.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.1ms\n",
      "Speed: 1.6ms preprocess, 78.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.3ms\n",
      "Speed: 1.5ms preprocess, 77.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.6ms\n",
      "Speed: 1.6ms preprocess, 78.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 74.4ms\n",
      "Speed: 1.6ms preprocess, 74.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.9ms\n",
      "Speed: 1.7ms preprocess, 77.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 72.7ms\n",
      "Speed: 1.4ms preprocess, 72.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 84.1ms\n",
      "Speed: 1.6ms preprocess, 84.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 72.7ms\n",
      "Speed: 1.6ms preprocess, 72.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.5ms\n",
      "Speed: 1.5ms preprocess, 78.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 73.7ms\n",
      "Speed: 1.5ms preprocess, 73.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.4ms\n",
      "Speed: 1.6ms preprocess, 78.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 82.4ms\n",
      "Speed: 1.5ms preprocess, 82.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.0ms\n",
      "Speed: 1.5ms preprocess, 78.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 76.6ms\n",
      "Speed: 3.1ms preprocess, 76.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.8ms\n",
      "Speed: 1.8ms preprocess, 79.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 80.8ms\n",
      "Speed: 1.5ms preprocess, 80.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.1ms\n",
      "Speed: 1.8ms preprocess, 79.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 75.4ms\n",
      "Speed: 1.8ms preprocess, 75.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 73.4ms\n",
      "Speed: 3.7ms preprocess, 73.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.4ms\n",
      "Speed: 1.6ms preprocess, 79.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.3ms\n",
      "Speed: 1.7ms preprocess, 79.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.8ms\n",
      "Speed: 1.6ms preprocess, 78.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 105.4ms\n",
      "Speed: 1.7ms preprocess, 105.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.5ms\n",
      "Speed: 1.4ms preprocess, 79.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.0ms\n",
      "Speed: 1.7ms preprocess, 77.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 75.9ms\n",
      "Speed: 1.8ms preprocess, 75.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 75.1ms\n",
      "Speed: 1.6ms preprocess, 75.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.2ms\n",
      "Speed: 1.7ms preprocess, 78.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.6ms\n",
      "Speed: 1.4ms preprocess, 77.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 80.6ms\n",
      "Speed: 1.7ms preprocess, 80.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 80.4ms\n",
      "Speed: 1.7ms preprocess, 80.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 74.2ms\n",
      "Speed: 1.8ms preprocess, 74.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 84.5ms\n",
      "Speed: 1.5ms preprocess, 84.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 78.8ms\n",
      "Speed: 1.6ms preprocess, 78.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 74.5ms\n",
      "Speed: 1.9ms preprocess, 74.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 75.0ms\n",
      "Speed: 1.6ms preprocess, 75.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 73.2ms\n",
      "Speed: 3.5ms preprocess, 73.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.0ms\n",
      "Speed: 1.4ms preprocess, 79.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.8ms\n",
      "Speed: 2.1ms preprocess, 79.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 74.6ms\n",
      "Speed: 1.7ms preprocess, 74.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 83.0ms\n",
      "Speed: 1.6ms preprocess, 83.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 74.2ms\n",
      "Speed: 2.0ms preprocess, 74.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 79.2ms\n",
      "Speed: 2.0ms preprocess, 79.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 79.2ms\n",
      "Speed: 1.4ms preprocess, 79.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.6ms\n",
      "Speed: 1.9ms preprocess, 78.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 73.3ms\n",
      "Speed: 3.0ms preprocess, 73.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 75.1ms\n",
      "Speed: 1.7ms preprocess, 75.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 76.6ms\n",
      "Speed: 1.6ms preprocess, 76.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 82.7ms\n",
      "Speed: 1.8ms preprocess, 82.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 75.2ms\n",
      "Speed: 1.4ms preprocess, 75.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 84.9ms\n",
      "Speed: 1.5ms preprocess, 84.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 82.0ms\n",
      "Speed: 1.6ms preprocess, 82.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 81.4ms\n",
      "Speed: 1.4ms preprocess, 81.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.4ms\n",
      "Speed: 2.3ms preprocess, 77.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 80.3ms\n",
      "Speed: 2.2ms preprocess, 80.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 81.0ms\n",
      "Speed: 1.9ms preprocess, 81.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 Eggs, 81.3ms\n",
      "Speed: 1.8ms preprocess, 81.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 80.3ms\n",
      "Speed: 1.8ms preprocess, 80.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 76.1ms\n",
      "Speed: 1.8ms preprocess, 76.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.2ms\n",
      "Speed: 1.7ms preprocess, 77.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 72.7ms\n",
      "Speed: 2.1ms preprocess, 72.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 76.6ms\n",
      "Speed: 1.7ms preprocess, 76.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 77.3ms\n",
      "Speed: 1.4ms preprocess, 77.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 Eggs, 78.3ms\n",
      "Speed: 1.6ms preprocess, 78.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import threading\n",
    "import cv2\n",
    "from queue import Queue\n",
    "from ultralytics import YOLO\n",
    "from yolox.tracker.byte_tracker import BYTETracker\n",
    "from types import SimpleNamespace\n",
    "import torch\n",
    "\n",
    "# Load YOLOv8 model\n",
    "# model.export(format=\"engine\", device=0)  # Convert to TensorRT (Use on Jetson/Low-Power devices)\n",
    "model = YOLO(\"./runs/detect/egg-counter/weights/best.pt\")  # Your trained model\n",
    "model.fuse()  # Fuse Conv2d and BatchNorm layers for faster inference\n",
    "torch.set_grad_enabled(False)  # Disable gradients for inference\n",
    "#model = model.half()  # Use half precision for faster inference (Use if your GPU supports it)\n",
    "\n",
    "# RTSP stream and resolution\n",
    "RTSP_URL = 'rtsp://admin:Egg%21Camera1@192.168.68.70:554/h264Preview_01_main'\n",
    "width, height = 1920, 1080\n",
    "\n",
    "# FFmpeg command with low latency options\n",
    "ffmpeg_cmd = [\n",
    "    'ffmpeg',\n",
    "    '-rtsp_transport', 'tcp',\n",
    "    '-fflags', 'nobuffer',\n",
    "    '-flags', 'low_delay',\n",
    "    '-analyzeduration', '0',\n",
    "    '-probesize', '32',\n",
    "    '-i', RTSP_URL,\n",
    "    '-f', 'image2pipe',\n",
    "    '-pix_fmt', 'bgr24',\n",
    "    '-vcodec', 'rawvideo',\n",
    "    '-vf', f'scale={width}:{height}',\n",
    "    '-r', '15',\n",
    "    '-'\n",
    "]\n",
    "\n",
    "# Setup tracker\n",
    "args = SimpleNamespace(\n",
    "    track_thresh=0.5,\n",
    "    track_buffer=15,\n",
    "    match_thresh=0.7,\n",
    "    min_box_area=100,\n",
    "    mot20=False,\n",
    "    frame_rate=15\n",
    ")\n",
    "tracker = BYTETracker(args)\n",
    "\n",
    "# Line for egg counting\n",
    "line_position = width//2\n",
    "counted_ids = set()\n",
    "total_count = 0\n",
    "    \n",
    "# Start ffmpeg subprocess\n",
    "process = subprocess.Popen(ffmpeg_cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, bufsize=10**8)\n",
    "\n",
    "frame_queue = Queue(maxsize=5)\n",
    "\n",
    "# Frame reader thread (non-blocking)\n",
    "def read_frames():\n",
    "    while True:\n",
    "        raw_frame = process.stdout.read(width * height * 3)\n",
    "        if not raw_frame:\n",
    "            continue\n",
    "        frame = np.frombuffer(raw_frame, dtype=np.uint8).reshape((height, width, 3)).copy()\n",
    "        if not frame_queue.full():\n",
    "            frame_queue.put(frame)\n",
    "\n",
    "threading.Thread(target=read_frames, daemon=True).start()\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    if frame_queue.empty():\n",
    "        continue\n",
    "    frame = frame_queue.get()\n",
    "\n",
    "    results = model(frame)[0]\n",
    "    detections = results.boxes\n",
    "\n",
    "    dets = []\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = float(box.conf[0])\n",
    "        if conf > 0.5:\n",
    "            dets.append([x1, y1, x2, y2, conf])\n",
    "    \n",
    "    if dets:\n",
    "        dets_tensor = torch.tensor(dets, dtype=torch.float32)\n",
    "        tracks = tracker.update(dets_tensor, frame.shape[:2], frame.shape)\n",
    "    else:\n",
    "        tracks = []\n",
    "\n",
    "    for track in tracks:\n",
    "        track_id = int(track.track_id)\n",
    "        x, y, w, h = track.tlwh\n",
    "        center_x = x + w / 2\n",
    "        center_y = y + h / 2\n",
    "\n",
    "        # Find the corresponding detection confidence (optional fallback = 0.0)\n",
    "        conf = 0.0\n",
    "        for det in dets:\n",
    "            if abs(det[0] - x) < 5 and abs(det[1] - y) < 5:\n",
    "                conf = det[4]\n",
    "                break\n",
    "\n",
    "        cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"ID:{track_id} | {conf:.2f}\", (int(x), int(y - 10)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "        # 🧠 Fix: should be y + h, not y + w\n",
    "        if track_id not in counted_ids and x < line_position < x + w:\n",
    "            counted_ids.add(track_id)\n",
    "            total_count += 1\n",
    "\n",
    "        cv2.circle(frame, (int(center_x), int(center_y)), 3, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.line(frame, (line_position, 0), (line_position, frame.shape[1]), (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Total Count: {total_count}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Egg Counter\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cv2.imwrite(\"test_frame.jpg\", frame)\n",
    "        break\n",
    "\n",
    "process.terminate()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4ba63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <0B7EB158-53DC-3403-8A49-22178CAB4612> /opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/egg-counter/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/egg-counter/lib/python3.10/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/egg-counter/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqueue\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Queue\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myolox\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbyte_tracker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BYTETracker\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SimpleNamespace\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ByteTrack/yolox/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python3\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding:utf-8 -*-\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m configure_module\n\u001b[1;32m      6\u001b[0m configure_module()\n\u001b[1;32m      8\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/ByteTrack/yolox/utils/__init__.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_logger\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LRScheduler\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msetup_env\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import threading\n",
    "import cv2\n",
    "from queue import Queue\n",
    "from ultralytics import YOLO\n",
    "from yolox.tracker.byte_tracker import BYTETracker\n",
    "from types import SimpleNamespace\n",
    "import torch\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"./runs/detect/egg-counter4/weights/best.pt\")  # Your trained model\n",
    "\n",
    "# RTSP stream and resolution\n",
    "RTSP_URL = 'rtsp://admin:Egg%21Camera1@192.168.68.70:554/h264Preview_01_main'\n",
    "width, height = 640, 380\n",
    "\n",
    "# FFmpeg command with low latency options\n",
    "ffmpeg_cmd = [\n",
    "    'ffmpeg',\n",
    "    '-rtsp_transport', 'tcp',\n",
    "    '-fflags', 'nobuffer',\n",
    "    '-flags', 'low_delay',\n",
    "    '-analyzeduration', '0',\n",
    "    '-probesize', '32',\n",
    "    '-i', RTSP_URL,\n",
    "    '-f', 'image2pipe',\n",
    "    '-pix_fmt', 'bgr24',\n",
    "    '-vcodec', 'rawvideo',\n",
    "    '-vf', f'scale={width}:{height}',\n",
    "    '-r', '10',\n",
    "    '-'\n",
    "]\n",
    "\n",
    "# Setup tracker\n",
    "args = SimpleNamespace(\n",
    "    track_thresh=0.5,\n",
    "    track_buffer=30,\n",
    "    match_thresh=0.7,\n",
    "    min_box_area=100,\n",
    "    mot20=False,\n",
    "    frame_rate=10\n",
    ")\n",
    "tracker = BYTETracker(args)\n",
    "\n",
    "# Line for egg counting\n",
    "line_position = 180\n",
    "counted_ids = set()\n",
    "total_count = 0\n",
    "    \n",
    "# Start ffmpeg subprocess\n",
    "process = subprocess.Popen(ffmpeg_cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, bufsize=10**8)\n",
    "\n",
    "frame_queue = Queue(maxsize=5)\n",
    "\n",
    "# Frame reader thread (non-blocking)\n",
    "def read_frames():\n",
    "    while True:\n",
    "        raw_frame = process.stdout.read(width * height * 3)\n",
    "        if not raw_frame:\n",
    "            continue\n",
    "        frame = np.frombuffer(raw_frame, dtype=np.uint8).reshape((height, width, 3)).copy()\n",
    "        if not frame_queue.full():\n",
    "            frame_queue.put(frame)\n",
    "\n",
    "threading.Thread(target=read_frames, daemon=True).start()\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    if frame_queue.empty():\n",
    "        continue\n",
    "    frame = frame_queue.get()\n",
    "\n",
    "    results = model(frame)[0]\n",
    "    detections = results.boxes\n",
    "\n",
    "    dets = []\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = float(box.conf[0])\n",
    "        if conf > 0.5:\n",
    "            dets.append([x1, y1, x2, y2, conf])\n",
    "    \n",
    "    if dets:\n",
    "        dets_tensor = torch.tensor(dets, dtype=torch.float32)\n",
    "        tracks = tracker.update(dets_tensor, frame.shape[:2], frame.shape)\n",
    "    else:\n",
    "        tracks = []\n",
    "\n",
    "    for track in tracks:\n",
    "        track_id = int(track.track_id)\n",
    "        x, y, w, h = track.tlwh\n",
    "        center_x = x + w / 2\n",
    "        center_y = y + h / 2\n",
    "\n",
    "        # Find the corresponding detection confidence (optional fallback = 0.0)\n",
    "        conf = 0.0\n",
    "        for det in dets:\n",
    "            if abs(det[0] - x) < 5 and abs(det[1] - y) < 5:\n",
    "                conf = det[4]\n",
    "                break\n",
    "\n",
    "        cv2.rectangle(frame, (int(x), int(y)), (int(x + w), int(y + h)), (0, 255, 255), 2)\n",
    "        cv2.putText(frame, f\"ID:{track_id} | {conf:.2f}\", (int(x), int(y - 10)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "        # 🧠 Fix: should be y + h, not y + w\n",
    "        if track_id not in counted_ids and y < line_position < y + h:\n",
    "            counted_ids.add(track_id)\n",
    "            total_count += 1\n",
    "\n",
    "        cv2.circle(frame, (int(center_x), int(center_y)), 3, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.line(frame, (0, line_position), (frame.shape[1], line_position), (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Total Count: {total_count}\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Egg Counter\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        cv2.imwrite(\"test_frame.jpg\", frame)\n",
    "        break\n",
    "\n",
    "process.terminate()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egg-counter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
